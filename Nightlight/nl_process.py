# -*- coding: utf-8 -*-
# ---------------------------------------------------------------------------
# nl_process.py
# Created on: 2021-04-20 16:02:28.00000
#   (generated by ArcGIS/ModelBuilder)
# Description: 
# ---------------------------------------------------------------------------

# Import arcpy module
import arcpy

arcpy.env.workspace = "D:\\Research\\WEBS\\Geo_data\\nightlight_working_data"

# Process: Add Join: add "all.shp" to the map first, delete the previous all_city file
inFeature = "all"
outFeature = "all_city"
joinTable = "D:\\Research\\WEBS\\Geo_data\\nightlight_working_data\\all_city_define.csv"

city_join_table = arcpy.AddJoin_management(inFeature, "FID", joinTable, "fid", "KEEP_COMMON")
arcpy.CopyFeatures_management(city_join_table, outFeature)


# Process: Erase gas flare: add "All_flare.shp" to the map first
All_flare = "All_flare"
all_city_erase_shp = "D:\\Research\\WEBS\\Geo_data\\nightlight_working_data\\all_city_erase.shp"

arcpy.Erase_analysis(outFeature, All_flare, all_city_erase_shp, "")


# Process: Extract by Mask: add "all_city_erase.shp" and all nightlight data to the map first
# Note: this is better than clipping to the city map. Clipping results in loss of some parts in city ID: 24, 30, 39, 54, 55, 58, 81, 87, 97, 102, 132, 143, 145, 152, 153, 166, 185, 198, 200
all_city_erase_shp = "D:\\Research\\WEBS\\Geo_data\\nightlight_working_data\\all_city_erase.shp"

x=2009
while x<2014:
    print str(x)
    arcpy.gp.ExtractByMask_sa("D:\\Research\\WEBS\\Geo_data\\nightlight\\harmonized nightlight data\\harmonized_data\\Harmonized_DN_NTL_"+str(x)+"_calDMSP.tif", all_city_erase_shp, "D:\\Research\\WEBS\\Geo_data\\nightlight_working_data\\NLetr"+str(x))
    x=x+1

x=2014
while x<2019:
    print str(x)
    arcpy.gp.ExtractByMask_sa("D:\\Research\\WEBS\\Geo_data\\nightlight\\harmonized nightlight data\\harmonized_data\\Harmonized_DN_NTL_"+str(x)+"_simVIIRS.tif", all_city_erase_shp, "D:\\Research\\WEBS\\Geo_data\\nightlight_working_data\\NLetr"+str(x))
    x=x+1

    

# Process: Zonal statistics: add "all_city_erase.shp" and all nightlight data from the above step to the map first
# 2019 data is proxied by 2018 data, just copy 2018 csv
all_city_erase_shp = "D:\\Research\\WEBS\\Geo_data\\nightlight_working_data\\all_city_erase.shp"

x=2009
while x<2019:
    print str(x)
    arcpy.gp.ZonalStatisticsAsTable_sa(all_city_erase_shp, "all_city_2", "D:\\Research\\WEBS\\Geo_data\\nightlight_working_data\\NLetr"+str(x), "D:\\Research\\WEBS\\Geo_data\\nightlight_working_data\\nl"+str(x)+".dbf", "DATA", "MEAN")
    x=x+1



# Process: Convert .dbf Table To CSV File: do not need to open .dbf data in arcgis
working_data = "D:\\Research\\WEBS\\Geo_data\\nightlight_working_data"

x=2009
while x<2019:
    print str(x)
    arcpy.TableToTable_conversion("D:\\Research\\WEBS\\Geo_data\\nightlight_working_data\\nl"+str(x)+".dbf", working_data, "nl"+str(x)+".csv")
    x=x+1


# Process: Calculate the area of polygons (city area = sum up the area of polygons inside the cities). It is not good to convert from degrees to km2 because degree conversion depends on latitude
all_city_erase_shp = "D:\\Research\\WEBS\\Geo_data\\nightlight_working_data\\all_city_erase.shp"
working_data = "D:\\Research\\WEBS\\Geo_data\\nightlight_working_data"

arcpy.AddGeometryAttributes_management(all_city_erase_shp, "AREA_GEODESIC", "", "SQUARE_KILOMETERS", "")
arcpy.TableToTable_conversion("D:\\Research\\WEBS\\Geo_data\\nightlight_working_data\\all_city_erase.shp", working_data, "area_data.csv")

